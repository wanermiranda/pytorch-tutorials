{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256*4*4,1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(1024,512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef0214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = nn.Sequential(\n",
    "#       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Flatten(start_dim=1)  ,\n",
    "#       nn.Linear(in_features=15232, out_features=120),\n",
    "#       nn.ReLU(),\n",
    "#       nn.Linear(in_features=120, out_features=60),\n",
    "#       nn.ReLU(),\n",
    "#       nn.Linear(in_features=60, out_features=2)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3876a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a00f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a9285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class DQN_BackBone(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.RMSprop),\n",
    "        memory=ReplayMemory(10000),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)        \n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(150)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(40)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=linear_input_size, out_features=self._outputs)\n",
    "#         self.out = nn.Linear(in_features=128, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "       \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return self.fc1(x.view(x.size(0), -1))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.999,\n",
    "    EPS_START = 0.5,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_net = DQN_BackBone(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d6ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58720399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bdab1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN_BackBone(conf=conf)\n",
    "policy_net.load_states_from(target_net)\n",
    "\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e673716",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = policy_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
