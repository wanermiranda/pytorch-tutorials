{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 75])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.5)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "\n",
    "#     screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea22d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256*4*4,1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(1024,512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = nn.Sequential(\n",
    "#       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Flatten(start_dim=1)  ,\n",
    "#       nn.Linear(in_features=15232, out_features=120),\n",
    "#       nn.ReLU(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2970f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80141db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40, 75])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ebb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class DQN_BackBone(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.RMSprop),\n",
    "        memory=ReplayMemory(10000),\n",
    "        screen_dims=ScreenDims(height=40, width=150),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)        \n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.width)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.height)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=linear_input_size, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "       \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return self.fc1(x.view(x.size(0), -1))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 256,\n",
    "    GAMMA = 0.5,\n",
    "    EPS_START = 0.2,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bacb63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "w, h= get_screen().shape[2:]\n",
    "target_net = DQN_BackBone(conf=conf, screen_dims=ScreenDims(height=h, width=w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df537280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8281, -0.6154]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_net(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -500\n",
      "10 14 -500\n",
      "20 29 -500\n",
      "30 46 -500\n",
      "40 65 -500\n",
      "50 86 -500\n",
      "60 109 -500\n",
      "70 134 -500\n",
      "80 161 -500\n",
      "90 190 -500\n",
      "100 221 -500\n",
      "110 254 -500\n",
      "120 289 -500\n",
      "130 326 -500\n",
      "140 365 -500\n",
      "150 406 -500\n",
      "160 449 -500\n",
      "170 494 -500\n",
      "180 541 -500\n",
      "190 590 -500\n",
      "200 641 0\n",
      "210 694 0\n"
     ]
    }
   ],
   "source": [
    "# def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "#     reward = 0\n",
    "    \n",
    "#     step_bonus = ((t // step_reward)+1)**2\n",
    "    \n",
    "#     if done:\n",
    "#         if t < max_reward // 2: \n",
    "#             reward = -(max_reward - t)\n",
    "#         else: \n",
    "#             reward = step_bonus + t*2\n",
    "#     elif t >= step_reward // 2: \n",
    "#         reward = step_bonus + t # promote the reward in steps \n",
    "#     else: \n",
    "#         reward = t\n",
    "\n",
    "#     return reward \n",
    "# for t in range(0, 220, 10):\n",
    "#     print (t, reward_function_step(False, t), reward_function_step(True, t),) \n",
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "    \n",
    "    step_bonus = ((t // step_reward)+1)**2\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -500\n",
    "        else: \n",
    "            reward = 0\n",
    "            \n",
    "    elif t >= step_reward // 2: \n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f7245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 10 -500\n",
      "10 100 10 -500\n",
      "20 200 10 -500\n",
      "30 300 10 -500\n",
      "40 400 10 -500\n",
      "50 500 10 -500\n",
      "60 600 10 -500\n",
      "70 700 10 -500\n",
      "80 800 10 -500\n",
      "90 900 10 -500\n",
      "100 1000 10 -500\n",
      "110 1100 10 -500\n",
      "120 1200 10 -500\n",
      "130 1300 10 -500\n",
      "140 1400 10 -500\n",
      "150 1500 10 -500\n",
      "160 1600 10 -500\n",
      "170 1700 10 -500\n",
      "180 1800 10 -500\n",
      "190 1900 10 -500\n",
      "200 2000 10 200\n",
      "210 2100 10 200\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step2(done, t, step_reward=10, max_reward=200):\n",
    "    \n",
    "    reward = 0\n",
    "\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -500\n",
    "        else: \n",
    "            reward = max_reward\n",
    "            \n",
    "    else: \n",
    "        reward = step_reward\n",
    "        \n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, t*10, reward_function_step2(False, t), reward_function_step2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9bd0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 100\n",
      "110 110 110\n",
      "120 120 120\n",
      "130 130 130\n",
      "140 140 140\n",
      "150 150 150\n",
      "160 160 160\n",
      "170 170 170\n",
      "180 180 180\n",
      "190 190 190\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbf8c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict = torch.load('model_1455_avg_131.0.pth')\n",
    "# target_net.load_state_dict(file_dict['state'])\n",
    "# target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-10 15:22:10.421618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-10 15:22:10.421642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN_BackBone(conf=conf, screen_dims=ScreenDims(height=h, width=w))\n",
    "policy_net.load_states_from(target_net)\n",
    "# policy_net._epsilon = 0.1\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations, \n",
    "                         reward_function=reward_function_step2\n",
    "                        )\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict = torch.load('model_1455_avg_131.0.pth')\n",
    "# target_net.load_state_dict(file_dict['state'])\n",
    "target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6805c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    \n",
    "    action = target_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d939e4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
