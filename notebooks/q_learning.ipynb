{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims,LayerConf, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 150])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n",
    "network_layout = [\n",
    "    LayerConf(input=3, kernel_size=5, stride=2, batch_norm=32), # 3 channels\n",
    "    LayerConf(input=32, kernel_size=5, stride=2, batch_norm=64),\n",
    "    LayerConf(input=64, kernel_size=5, stride=2, batch_norm=32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.999,\n",
    "    EPS_START = 0.5,\n",
    "    EPS_MIN = 0.01,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bacb63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "target_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 30 -190\n",
      "20 50 -180\n",
      "30 70 -170\n",
      "40 90 -160\n",
      "50 110 -150\n",
      "60 130 -140\n",
      "70 150 -130\n",
      "80 170 -120\n",
      "90 190 -110\n",
      "100 210 -100\n",
      "110 230 -90\n",
      "120 250 -80\n",
      "130 270 -70\n",
      "140 290 -60\n",
      "150 310 -50\n",
      "160 330 -40\n",
      "170 350 -30\n",
      "180 370 -20\n",
      "190 390 -10\n",
      "200 410 200\n",
      "210 430 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d19449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 -100\n",
      "110 110 -90\n",
      "120 120 -80\n",
      "130 130 -70\n",
      "140 140 -60\n",
      "150 150 -50\n",
      "160 160 -40\n",
      "170 170 -30\n",
      "180 180 -20\n",
      "190 190 -10\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17e60ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 100\n",
      "110 110 110\n",
      "120 120 120\n",
      "130 130 130\n",
      "140 140 140\n",
      "150 150 150\n",
      "160 160 160\n",
      "170 170 170\n",
      "180 180 180\n",
      "190 190 190\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 19:34:55.921551: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-03 19:34:55.921575: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)\n",
    "policy_net.load_states_from(target_net)\n",
    "\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7950d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = policy_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc9b466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
