{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 187])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Grayscale(num_output_channels=1),\n",
    "                    T.Resize(100),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.5)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "#     Strip off the edges, so that we have a square image centered on a cart\n",
    "\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = 1- (np.ascontiguousarray(screen, dtype=np.float32) / 255)\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).numpy()[0],\n",
    "           interpolation='none', cmap='gray')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea22d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256*4*4,1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(1024,512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = nn.Sequential(\n",
    "#       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Flatten(start_dim=1)  ,\n",
    "#       nn.Linear(in_features=15232, out_features=120),\n",
    "#       nn.ReLU(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2970f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80141db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 187])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ebb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class DQN_BackBone_Simple(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.Adadelta),\n",
    "        memory=ReplayMemory(10000),\n",
    "        screen_dims=ScreenDims(height=40, width=150),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2)        \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 3, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.width)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.height)))\n",
    "        linear_input_size = convw * convh * 128\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=linear_input_size, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "       \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "\n",
    "        return self.fc2(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80336831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torchvision.models as models\n",
    "\n",
    "class DQN_BackBone_NET(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.Adadelta),\n",
    "        memory=ReplayMemory(10000),\n",
    "        screen_dims=ScreenDims(height=40, width=150),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "        \n",
    "        self._net = models.resnet18(pretrained=False)\n",
    "        for idx, child in enumerate(self._net.children()):\n",
    "            if idx < 5: # Traning only the last sequential layers\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "        self._net.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, bias=False)\n",
    "        self._net.fc = nn.Linear(in_features=512, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "        return self._net(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 64,\n",
    "    GAMMA = .99,\n",
    "    EPS_START = 0.10,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f940cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN_Backbone_NET = partial(DQN_BackBone_NET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacb63a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN_BackBone_NET(\n",
       "  (_net): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, h= get_screen().shape[2:]\n",
    "target_net = DQN_BackBone_NET(conf=conf, screen_dims=ScreenDims(height=h, width=w))\n",
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df537280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2931, 0.2286]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_net(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -500\n",
      "10 14 -500\n",
      "20 29 -500\n",
      "30 46 -500\n",
      "40 65 -500\n",
      "50 86 -500\n",
      "60 109 -500\n",
      "70 134 -500\n",
      "80 161 -500\n",
      "90 190 -500\n",
      "100 221 -500\n",
      "110 254 -500\n",
      "120 289 -500\n",
      "130 326 -500\n",
      "140 365 -500\n",
      "150 406 -500\n",
      "160 449 -500\n",
      "170 494 -500\n",
      "180 541 -500\n",
      "190 590 -500\n",
      "200 641 0\n",
      "210 694 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "    \n",
    "    step_bonus = ((t // step_reward)+1)**2\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -500\n",
    "        else: \n",
    "            reward = 0\n",
    "            \n",
    "    elif t >= step_reward // 2: \n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03504ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 10 -200\n",
      "10 100 10 -200\n",
      "20 200 10 -200\n",
      "30 300 10 -200\n",
      "40 400 10 -200\n",
      "50 500 10 -200\n",
      "60 600 10 -200\n",
      "70 700 10 -200\n",
      "80 800 10 -200\n",
      "90 900 10 -200\n",
      "100 1000 10 -200\n",
      "110 1100 10 -200\n",
      "120 1200 10 -200\n",
      "130 1300 10 -200\n",
      "140 1400 10 -200\n",
      "150 1500 10 -200\n",
      "160 1600 10 -200\n",
      "170 1700 10 -200\n",
      "180 1800 10 -200\n",
      "190 1900 10 -200\n",
      "200 2000 10 200\n",
      "210 2100 10 200\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step2(done, t, step_reward=10, max_reward=200):\n",
    "    \n",
    "    reward = 0\n",
    "\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -200\n",
    "        else: \n",
    "            reward = max_reward\n",
    "            \n",
    "    else: \n",
    "        reward = step_reward\n",
    "        \n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, t*10, reward_function_step2(False, t), reward_function_step2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9bd0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 -1\n",
      "10 10 -1\n",
      "20 10 -1\n",
      "30 10 -1\n",
      "40 10 -1\n",
      "50 10 -1\n",
      "60 10 -1\n",
      "70 10 -1\n",
      "80 10 -1\n",
      "90 10 -1\n",
      "100 10 -1\n",
      "110 20 -1\n",
      "120 20 -1\n",
      "130 20 -1\n",
      "140 20 -1\n",
      "150 20 -1\n",
      "160 20 -1\n",
      "170 20 -1\n",
      "180 20 -1\n",
      "190 20 -1\n",
      "200 20 -1\n",
      "210 30 -1\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, steps, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        reward = -1\n",
    "    else:\n",
    "        reward = 10\n",
    "        if steps > 100:\n",
    "            reward += 10\n",
    "        if steps > 200:\n",
    "            reward += 10\n",
    "        if steps > 300:\n",
    "            reward += 10\n",
    "\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbf8c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict = torch.load('model_1455_avg_131.0.pth')\n",
    "# target_net.load_state_dict(file_dict['state'])\n",
    "# target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN_BackBone_NET(conf=conf, screen_dims=ScreenDims(height=h, width=w))\n",
    "policy_net.load_states_from(target_net)\n",
    "# policy_net._epsilon = 0.1\n",
    "durations = fit_networks(policy_net, None, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations, \n",
    "                         reward_function=reward_function_linear2\n",
    "                        )\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = torch.load('model_536_avg_178.1999969482422.pth')\n",
    "target_net.load_state_dict(file_dict['state'])\n",
    "target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6805c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    \n",
    "    action = target_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9ec73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
