{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims,LayerConf, DQNConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 150])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n",
    "network_layout = [\n",
    "    LayerConf(input=3, kernel_size=5, stride=2, batch_norm=32), # 3 channels\n",
    "    LayerConf(input=32, kernel_size=5, stride=2, batch_norm=64),\n",
    "    LayerConf(input=64, kernel_size=5, stride=2, batch_norm=32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.99,\n",
    "    EPS_START = 1.0,\n",
    "    EPS_MIN = 0.0001,\n",
    "    EPS_DECAY = 0.999,\n",
    "    TARGET_UPDATE = 10, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bacb63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "target_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 30 -190\n",
      "20 50 -180\n",
      "30 70 -170\n",
      "40 90 -160\n",
      "50 110 -150\n",
      "60 130 -140\n",
      "70 150 -130\n",
      "80 170 -120\n",
      "90 190 -110\n",
      "100 210 -100\n",
      "110 230 -90\n",
      "120 250 -80\n",
      "130 270 -70\n",
      "140 290 -60\n",
      "150 310 -50\n",
      "160 330 -40\n",
      "170 350 -30\n",
      "180 370 -20\n",
      "190 390 -10\n",
      "200 410 200\n",
      "210 430 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d19449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 -100\n",
      "110 110 -90\n",
      "120 120 -80\n",
      "130 130 -70\n",
      "140 140 -60\n",
      "150 150 -50\n",
      "160 160 -40\n",
      "170 170 -30\n",
      "180 180 -20\n",
      "190 190 -10\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "910b0022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 -100\n",
      "110 110 -90\n",
      "120 120 -80\n",
      "130 130 -70\n",
      "140 140 -60\n",
      "150 150 -50\n",
      "160 160 -40\n",
      "170 170 -30\n",
      "180 180 -20\n",
      "190 190 -10\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 14:53:38.384732: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-03 14:53:38.384757: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1000\n",
    "# restart policy net\n",
    "policy_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)\n",
    "policy_net.load_states_from(target_net)\n",
    "policy_net._conf.EPS_START = 0.01\n",
    "\n",
    "durations = DQN.fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations, \n",
    "                            reward_function=reward_function_linear2)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
