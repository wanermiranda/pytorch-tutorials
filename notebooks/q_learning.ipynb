{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 150])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a60f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256*4*4,1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(1024,512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98746fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = nn.Sequential(\n",
    "#       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Flatten(start_dim=1)  ,\n",
    "#       nn.Linear(in_features=15232, out_features=120),\n",
    "#       nn.ReLU(),\n",
    "#       nn.Linear(in_features=120, out_features=60),\n",
    "#       nn.ReLU(),\n",
    "#       nn.Linear(in_features=60, out_features=2)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f3366c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e845be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40, 150])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8911fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class DQN_BackBone(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.RMSprop),\n",
    "        memory=ReplayMemory(10000),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)        \n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(150)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(40)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=linear_input_size, out_features=128)\n",
    "        self.out = nn.Linear(in_features=128, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "       \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.999,\n",
    "    EPS_START = 0.5,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb63a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_net = DQN_BackBone(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58720399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270bda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN_BackBone(conf=conf)\n",
    "policy_net.load_states_from(target_net)\n",
    "\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb3b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = policy_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
