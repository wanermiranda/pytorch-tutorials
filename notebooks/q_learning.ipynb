{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 187])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Grayscale(num_output_channels=1),\n",
    "                    T.Resize(100),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.5)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "#     Strip off the edges, so that we have a square image centered on a cart\n",
    "\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = 1- (np.ascontiguousarray(screen, dtype=np.float32) / 255)\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).numpy()[0],\n",
    "           interpolation='none', cmap='gray')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()\n",
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ea22d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential(\n",
    "#     nn.Conv2d(3,32,kernel_size=3,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.MaxPool2d(2,2),\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Linear(256*4*4,1024),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(1024,512),\n",
    "#     nn.ReLU(),\n",
    "#     nn.Linear(512,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "847e7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential = nn.Sequential(\n",
    "#       nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "#       nn.ReLU(),\n",
    "#       nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#       nn.Flatten(start_dim=1)  ,\n",
    "#       nn.Linear(in_features=15232, out_features=120),\n",
    "#       nn.ReLU(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2970f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequential(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b80141db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 100, 187])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ebb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "class DQN_BackBone_Simple(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.Adadelta),\n",
    "        memory=ReplayMemory(10000),\n",
    "        screen_dims=ScreenDims(height=40, width=150),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2)        \n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 3, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.width)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_dims.height)))\n",
    "        linear_input_size = convw * convh * 128\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=linear_input_size, out_features=512)\n",
    "        self.fc2 = nn.Linear(in_features=512, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "       \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "\n",
    "        x = F.relu(self.fc1(x.view(x.size(0), -1)))\n",
    "\n",
    "        return self.fc2(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80336831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torchvision.models as models\n",
    "\n",
    "class DQN_BackBone_NET(DQN): \n",
    "    def __init__(\n",
    "        self,\n",
    "        device=\"cuda\",\n",
    "        conf: DQNConf = DQNConf(),\n",
    "        optimizer_partial=partial(optim.Adadelta),\n",
    "        memory=ReplayMemory(10000),\n",
    "        screen_dims=ScreenDims(height=40, width=150),\n",
    "        outputs=2\n",
    "    ):\n",
    "        super().__init__(device, conf, optimizer_partial, memory, outputs)\n",
    "        \n",
    "        self._net = models.resnet18(pretrained=False)\n",
    "#         for idx, child in enumerate(self._net.children()):\n",
    "#             if idx < 7: # Traning only the last sequential layers\n",
    "#                 for param in child.parameters():\n",
    "#                     param.requires_grad = False\n",
    "\n",
    "        self._net.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, bias=False)\n",
    "        self._net.fc = nn.Linear(in_features=512, out_features=self._outputs)\n",
    "\n",
    "        self._send_to_device(device=device)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(self._device)\n",
    "        return self._net(x)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 32,\n",
    "    GAMMA = .99,\n",
    "    EPS_START = 0.10,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f940cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DQN_Backbone_NET = partial(DQN_BackBone_Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacb63a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DQN_BackBone_NET(\n",
       "  (_net): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, h= get_screen().shape[2:]\n",
    "target_net = DQN_BackBone_NET(conf=conf, screen_dims=ScreenDims(height=h, width=w))\n",
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df537280",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4355, -0.7809]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_net(get_screen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -500\n",
      "10 14 -500\n",
      "20 29 -500\n",
      "30 46 -500\n",
      "40 65 -500\n",
      "50 86 -500\n",
      "60 109 -500\n",
      "70 134 -500\n",
      "80 161 -500\n",
      "90 190 -500\n",
      "100 221 -500\n",
      "110 254 -500\n",
      "120 289 -500\n",
      "130 326 -500\n",
      "140 365 -500\n",
      "150 406 -500\n",
      "160 449 -500\n",
      "170 494 -500\n",
      "180 541 -500\n",
      "190 590 -500\n",
      "200 641 0\n",
      "210 694 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "    \n",
    "    step_bonus = ((t // step_reward)+1)**2\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -500\n",
    "        else: \n",
    "            reward = 0\n",
    "            \n",
    "    elif t >= step_reward // 2: \n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03504ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 10 -200\n",
      "10 100 10 -200\n",
      "20 200 10 -200\n",
      "30 300 10 -200\n",
      "40 400 10 -200\n",
      "50 500 10 -200\n",
      "60 600 10 -200\n",
      "70 700 10 -200\n",
      "80 800 10 -200\n",
      "90 900 10 -200\n",
      "100 1000 10 -200\n",
      "110 1100 10 -200\n",
      "120 1200 10 -200\n",
      "130 1300 10 -200\n",
      "140 1400 10 -200\n",
      "150 1500 10 -200\n",
      "160 1600 10 -200\n",
      "170 1700 10 -200\n",
      "180 1800 10 -200\n",
      "190 1900 10 -200\n",
      "200 2000 10 200\n",
      "210 2100 10 200\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step2(done, t, step_reward=10, max_reward=200):\n",
    "    \n",
    "    reward = 0\n",
    "\n",
    "    \n",
    "    if done:\n",
    "        if t < max_reward: \n",
    "            reward = -200\n",
    "        else: \n",
    "            reward = max_reward\n",
    "            \n",
    "    else: \n",
    "        reward = step_reward\n",
    "        \n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, t*10, reward_function_step2(False, t), reward_function_step2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9bd0b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10 -1\n",
      "10 10 -1\n",
      "20 10 -1\n",
      "30 10 -1\n",
      "40 10 -1\n",
      "50 10 -1\n",
      "60 10 -1\n",
      "70 10 -1\n",
      "80 10 -1\n",
      "90 10 -1\n",
      "100 10 -1\n",
      "110 20 -1\n",
      "120 20 -1\n",
      "130 20 -1\n",
      "140 20 -1\n",
      "150 20 -1\n",
      "160 20 -1\n",
      "170 20 -1\n",
      "180 20 -1\n",
      "190 20 -1\n",
      "200 20 -1\n",
      "210 30 -1\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, steps, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        reward = -1\n",
    "    else:\n",
    "        reward = 10\n",
    "        if steps > 100:\n",
    "            reward += 10\n",
    "        if steps > 200:\n",
    "            reward += 10\n",
    "        if steps > 300:\n",
    "            reward += 10\n",
    "\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbf8c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict = torch.load('model_1455_avg_131.0.pth')\n",
    "# target_net.load_state_dict(file_dict['state'])\n",
    "# target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-17 03:04:48.981193: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-17 03:04:48.981219: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN_BackBone_NET(conf=conf, screen_dims=ScreenDims(height=h, width=w))\n",
    "policy_net.load_states_from(target_net)\n",
    "# policy_net._epsilon = 0.1\n",
    "durations = fit_networks(policy_net, None, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations, \n",
    "                         reward_function=reward_function_linear2\n",
    "                        )\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dict = torch.load('model_1455_avg_131.0.pth')\n",
    "# target_net.load_state_dict(file_dict['state'])\n",
    "target_net._epsilon = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6805c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    \n",
    "    action = target_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
