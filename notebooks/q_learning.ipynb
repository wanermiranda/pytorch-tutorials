{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims,LayerConf, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 150])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n",
    "network_layout = [\n",
    "    LayerConf(input=3, kernel_size=5, stride=2, batch_norm=32), # 3 channels\n",
    "    LayerConf(input=32, kernel_size=5, stride=2, batch_norm=64),\n",
    "    LayerConf(input=64, kernel_size=5, stride=2, batch_norm=32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.999,\n",
    "    EPS_START = 0.9,\n",
    "    EPS_MIN = 0.05,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bacb63a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "target_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58720399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 30 -190\n",
      "20 50 -180\n",
      "30 70 -170\n",
      "40 90 -160\n",
      "50 110 -150\n",
      "60 130 -140\n",
      "70 150 -130\n",
      "80 170 -120\n",
      "90 190 -110\n",
      "100 210 -100\n",
      "110 230 -90\n",
      "120 250 -80\n",
      "130 270 -70\n",
      "140 290 -60\n",
      "150 310 -50\n",
      "160 330 -40\n",
      "170 350 -30\n",
      "180 370 -20\n",
      "190 390 -10\n",
      "200 410 200\n",
      "210 430 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92d19449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 -100\n",
      "110 110 -90\n",
      "120 120 -80\n",
      "130 130 -70\n",
      "140 140 -60\n",
      "150 150 -50\n",
      "160 160 -40\n",
      "170 170 -30\n",
      "180 180 -20\n",
      "190 190 -10\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "809c29f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 -200\n",
      "10 10 -190\n",
      "20 20 -180\n",
      "30 30 -170\n",
      "40 40 -160\n",
      "50 50 -150\n",
      "60 60 -140\n",
      "70 70 -130\n",
      "80 80 -120\n",
      "90 90 -110\n",
      "100 100 -100\n",
      "110 110 -90\n",
      "120 120 -80\n",
      "130 130 -70\n",
      "140 140 -60\n",
      "150 150 -50\n",
      "160 160 -40\n",
      "170 170 -30\n",
      "180 180 -20\n",
      "190 190 -10\n",
      "200 200 200\n",
      "210 210 210\n"
     ]
    }
   ],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-03 17:17:32.465680: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-10-03 17:17:32.465704: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_873020/2699533937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPS_START\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m durations = fit_networks(policy_net, target_net, env, get_screen, \n\u001b[0m\u001b[1;32m      8\u001b[0m                              \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                              \u001b[0mepisode_durations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepisode_durations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/projects/pytorch-tutorials/notebooks/../wompth/models/dqn.py\u001b[0m in \u001b[0;36mfit_networks\u001b[0;34m(policy_net, target_net, env, get_screen, num_episodes, episode_durations, reward_function)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;31m# Perform one step of the optimization (on the policy network)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mpolicy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/data/projects/pytorch-tutorials/notebooks/../wompth/models/dqn.py\u001b[0m in \u001b[0;36moptimize_model\u001b[0;34m(self, target_net, criterion)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# state value or 0 in case the state was final.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mnext_state_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         next_state_values[non_final_mask] = (\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mtarget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_final_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_episodes = conf.MAX_EP\n",
    "# restart policy net\n",
    "policy_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)\n",
    "policy_net.load_states_from(target_net)\n",
    "\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations, \n",
    "                            reward_function=reward_function_linear2)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e1e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = policy_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de9c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
