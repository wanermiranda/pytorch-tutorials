{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56739ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275b8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wompth.models.dqn import Transition, ReplayMemory, DQN, ScreenDims,LayerConf, DQNConf, fit_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a5ec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gorigan/anaconda3/envs/pytorch/lib/python3.8/site-packages/torchvision/transforms/transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width)\n",
    "    slice_range = slice(view_width)\n",
    "#     cart_location = get_cart_location(screen_width)\n",
    "#     if cart_location < view_width // 2:\n",
    "#         slice_range = slice(view_width)\n",
    "#     elif cart_location > (screen_width - view_width // 2):\n",
    "#         slice_range = slice(-view_width, None)\n",
    "#     else:\n",
    "#         slice_range = slice(cart_location - view_width // 2,\n",
    "#                             cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577f3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 40, 150])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_screen().cpu().squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90d1b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8f36bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "screen_dims = ScreenDims(screen_height, screen_width)\n",
    "network_layout = [\n",
    "    LayerConf(input=3, kernel_size=5, stride=2, batch_norm=32), # 3 channels\n",
    "    LayerConf(input=32, kernel_size=5, stride=2, batch_norm=64),\n",
    "    LayerConf(input=64, kernel_size=5, stride=2, batch_norm=32),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e3d1489",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'EPS_MIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_922026/2645949847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m conf = DQNConf(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mGAMMA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mEPS_START\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mEPS_MIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'EPS_MIN'"
     ]
    }
   ],
   "source": [
    "conf = DQNConf(\n",
    "    BATCH_SIZE = 128,\n",
    "    GAMMA = 0.999,\n",
    "    EPS_START = 0.5,\n",
    "    TARGET_UPDATE = 10, \n",
    "    MAX_EPISODES = 1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d88ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_net._linear_input_size, target_net._epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target_net.load_state_dict(policy_net.state_dict())\n",
    "# target_net.eval()\n",
    "\n",
    "\n",
    "def moving_average_pth(x, w=10):\n",
    "    kernel = [1/w] * w\n",
    "    ts_tensor = torch.Tensor(x).reshape(1, 1, -1)\n",
    "    kernel_tensor = torch.Tensor(kernel).reshape(1, 1, -1)\n",
    "    return F.conv1d(ts_tensor, kernel_tensor).reshape(-1)\n",
    "\n",
    "def plot_durations(i_episode, episode_durations):\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel(f'Episode {i_episode}')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    means = moving_average_pth(durations_t, conf.TARGET_UPDATE)\n",
    "    plt.plot(means.numpy())\n",
    "    display.display(plt.gcf())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58720399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_step(done, t, step_reward=10, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    elif t >= step_reward: \n",
    "        step_bonus = ((t // step_reward)+1)*10\n",
    "        reward = step_bonus + t # promote the reward in steps \n",
    "    else: \n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_step(False, t), reward_function_step(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= max_reward:\n",
    "            reward = t  # discounted steps\n",
    "        else: \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear(False, t), reward_function_linear(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5179bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function_linear2(done, t, max_reward=200):\n",
    "    reward = 0\n",
    "\n",
    "    if done:\n",
    "        if t >= (max_reward /2) :\n",
    "            reward = t  # discounted steps\n",
    "        else:             \n",
    "            reward = -(max_reward - t)\n",
    "    else:\n",
    "        reward = t\n",
    "\n",
    "    return reward \n",
    "for t in range(0, 220, 10):\n",
    "    print (t, reward_function_linear2(False, t), reward_function_linear2(True, t),) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5615a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_durations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19308a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_episodes = conf.MAX_EPISODES\n",
    "# restart policy net\n",
    "policy_net = DQN(conf=conf, layout=network_layout, screen_dims=screen_dims, outputs=n_actions)\n",
    "policy_net.load_states_from(target_net)\n",
    "\n",
    "durations = fit_networks(policy_net, target_net, env, get_screen, \n",
    "                             num_episodes=num_episodes, \n",
    "                             episode_durations=episode_durations)\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_average_pth(episode_durations[:1000], 2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e84c902",
   "metadata": {},
   "outputs": [],
   "source": [
    "str(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa63a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515eb2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen\n",
    "for t in count():\n",
    "    # Select and perform an action\n",
    "    action = policy_net.select_action(state)\n",
    "    _, reward, done, _ = env.step(action.item())\n",
    "\n",
    "    # Observe new state\n",
    "    last_screen = current_screen\n",
    "    current_screen = get_screen()\n",
    "    if not done:\n",
    "        next_state = current_screen - last_screen\n",
    "    else:\n",
    "        next_state = None\n",
    "    \n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        episode_durations.append(t + 1)\n",
    "        print(t)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe1f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
